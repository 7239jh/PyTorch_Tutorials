{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[1, 1],\n",
      "        [1, 1]])\n",
      "tensor([[0.7261, 0.0053],\n",
      "        [0.5790, 0.9768]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "data=[[1,2],[3,4]]\n",
    "np_array=np.array(data)\n",
    "x_np=torch.from_numpy(np_array) # 넘파이에서 텐서로 변환\n",
    "x=torch.tensor(data) # 데이터에서 직접 텐서로 변환\n",
    "x_ones=torch.ones_like(x) # 텐서를 다 1로 변환\n",
    "x_rand=torch.rand_like(x,dtype=float) # 텐서를 다 0~1 사이의 랜덤 난수로 변환\n",
    "print(np_array)\n",
    "print(x_np)\n",
    "print(x)\n",
    "print(x_ones)\n",
    "print(x_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8362, 0.5184, 0.7068],\n",
      "        [0.5746, 0.5326, 0.9361]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape=(2,3,)\n",
    "rand_tensor=torch.rand(shape) # 지정한 차원의 랜덤 텐서 \n",
    "ones_tensor = torch.ones(shape) # 지정한 차원의 1로 채워진 텐서\n",
    "zeros_tensor=torch.zeros(shape) # 지정한 차원의 0으로 채워진 텐서\n",
    "print(rand_tensor)\n",
    "print(ones_tensor)\n",
    "print(zeros_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서의 속성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "torch.float32\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "tensor=torch.rand(3,4)\n",
    "print(tensor.shape) # 텐서의 차원\n",
    "print(tensor.dtype) # 텐서의 타입\n",
    "print(tensor.device) # 텐서의 디바이스"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1.])\n",
      "tensor([1., 1., 1., 1.])\n",
      "tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    tensor=tensor.to('cuda') # GPU가 있다면 텐서를 GPU로 연산\n",
    "   \n",
    "tensor=torch.ones(4,4)\n",
    "print(tensor[0]) # 텐서의 첫째 행\n",
    "print(tensor[:,0]) # 텐서의 첫째열\n",
    "print(tensor[...,-1]) # 텐서의 마지막 열\n",
    "tensor[:,1]=0 # 텐서의 두번쨰열 0으로 치환\n",
    "print(tensor) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1=torch.cat([tensor,tensor,tensor],dim=1) # 가로방향으로 병합\n",
    "t2=torch.cat([tensor,tensor,tensor],dim=0) # 세로방향으로 병합\n",
    "print(t1)\n",
    "print(t2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n",
      "tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "# 행렬곱 연산(y1=y2=y3)\n",
    "y1= tensor @ tensor.T\n",
    "y2= tensor.matmul(tensor.T)\n",
    "y3= torch.rand_like(y1)\n",
    "torch.matmul(tensor,tensor.T, out=y3)\n",
    "print(y1)\n",
    "print(y2)\n",
    "print(y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 요소별 곱(z1=z2=z3)\n",
    "z1=tensor*tensor\n",
    "z2=tensor.mul(tensor)\n",
    "z3=torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out=z3)\n",
    "print(z1)\n",
    "print(z2)\n",
    "print(z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.)\n",
      "12.0 <class 'float'>\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "agg=tensor.sum() # 텐서안의 모든 값의 총합을 텐서로 출력\n",
    "agg_item=agg.item() # 텐서에서 숫자값으로 변환\n",
    "print(agg)\n",
    "print(agg_item, type(agg_item))\n",
    "tensor.add_(5)  # 텐서의 모든원소에 5씩 더함\n",
    "print(tensor) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy 변환(Bridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t= torch.ones(5) # 차원5인 1로 채워진 텐서\n",
    "print(t)\n",
    "n=t.numpy() # 텐서를 넘파이로 변환\n",
    "print(n)\n",
    "t.add_(1) # 텐서의 모든 원소에 1씩 더함\n",
    "print(t)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "n=np.ones(5) # 차원 5인 1로 채워진 넘파이 생성\n",
    "print(n)\n",
    "t=torch.from_numpy(n) # 넘파이 텐서로 변환\n",
    "print(t)\n",
    "np.add(n,1,out=n) # 넘파이의 모든 원소에 1씩 더함\n",
    "print(n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_jupyter",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Oct 13 2022, 21:23:06) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
